# Lightautoml Addons

[_Documentation generated by Documatic_](https://www.documatic.com)

<!---Documatic-section-Codebase Structure-start--->
## Codebase Structure

<!---Documatic-block-system_architecture-start--->
```mermaid
None
```
<!---Documatic-block-system_architecture-end--->

# #
<!---Documatic-section-Codebase Structure-end--->

<!---Documatic-section-lightautoml.addons.interpretation.utils.untokenize-start--->
## [lightautoml.addons.interpretation.utils.untokenize](3-lightautoml_addons.md#lightautoml.addons.interpretation.utils.untokenize)

<!---Documatic-section-untokenize-start--->
<!---Documatic-block-lightautoml.addons.interpretation.utils.untokenize-start--->
<details>
	<summary><code>lightautoml.addons.interpretation.utils.untokenize</code> code snippet</summary>

```python
def untokenize(raw: str, tokens: List[str], return_mask: bool=False, token_sym: Any=True, untoken_sym: Any=False) -> T_untokenized:
    mask = []
    untokenized = []
    pos = raw.find(tokens[0])
    if pos != 0:
        untokenized.append(raw[:pos])
        mask.append(untoken_sym)
        raw = raw[pos:]
    prev_token = tokens[0]
    for token in tokens[1:]:
        raw = raw[len(prev_token):]
        pos = raw.find(token)
        untokenized.append(prev_token)
        mask.append(token_sym)
        if pos:
            mask.append(untoken_sym)
            untokenized.append(raw[:pos])
        prev_token = token
        raw = raw[pos:]
    untokenized.append(prev_token)
    mask.append(token_sym)
    cur = len(prev_token)
    if cur != len(raw):
        untokenized.append(raw[cur:])
        mask.append(untoken_sym)
    if return_mask:
        return (untokenized, mask)
    return untokenized
```
</details>
<!---Documatic-block-lightautoml.addons.interpretation.utils.untokenize-end--->
<!---Documatic-section-untokenize-end--->

# #
<!---Documatic-section-lightautoml.addons.interpretation.utils.untokenize-end--->

[_Documentation generated by Documatic_](https://www.documatic.com)